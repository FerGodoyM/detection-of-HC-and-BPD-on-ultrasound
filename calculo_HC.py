# ==============================================================
# VERSI√ìN CORREGIDA - VALIDACI√ìN ADAPTATIVA
# ==============================================================

import tensorflow as tf
import numpy as np
import cv2
import pandas as pd
from scipy import ndimage
from skimage import morphology
import os
import matplotlib.pyplot as plt

# Rutas base
BASE_DIR = r"C:\Users\ferna\OneDrive\Escritorio\PROYECTO OBSTETRICIA"
DATASET_DIR = os.path.join(BASE_DIR, "DATASET HC18")
TRAIN_DIR = os.path.join(DATASET_DIR, "training_set")
TEST_DIR = os.path.join(DATASET_DIR, "test_set")
MODEL_PATH = os.path.join(BASE_DIR, "unet_hc18_best.h5")

# Cargar modelo una sola vez (manejo de excepciones por si falta)
try:
    model = tf.keras.models.load_model(MODEL_PATH)
except Exception as e:
    print(f"‚ö†Ô∏è No se pudo cargar el modelo en '{MODEL_PATH}': {e}")
    model = None

# Cargar CSVs (cache en variables globales)
_train_df = None
_test_df = None

def _load_csv_data():
    global _train_df, _test_df
    if _train_df is None:
        train_csv = os.path.join(DATASET_DIR, "training_set_pixel_size_and_HC.csv")
        if os.path.isfile(train_csv):
            _train_df = pd.read_csv(train_csv)
        else:
            _train_df = pd.DataFrame(columns=["filename","pixel size(mm)","head circumference (mm)"])
    if _test_df is None:
        test_csv = os.path.join(DATASET_DIR, "test_set_pixel_size.csv")
        if os.path.isfile(test_csv):
            _test_df = pd.read_csv(test_csv)
        else:
            _test_df = pd.DataFrame(columns=["filename","pixel size(mm)"])

_load_csv_data()

def _select_row(df, img_id):
    """Selecciona fila m√°s apropiada para un id (preferencia *_HC.png exacto)."""
    # Primero coincidencia exacta id_HC.png
    exact = df[df['filename'] == f"{img_id}_HC.png"]
    if not exact.empty:
        return exact.iloc[0]
    # Luego filas que contienen id (duplicados _2HC etc.)
    subset = df[df['filename'].str.startswith(f"{img_id}")]
    if not subset.empty:
        # Si hay varias, tomar promedio de numeric columns
        if 'head circumference (mm)' in subset.columns:
            avg_pixel = subset['pixel size(mm)'].astype(float).mean()
            avg_hc = subset['head circumference (mm)'].astype(float).mean()
            return pd.Series({
                'filename': f"{img_id}_HC.png",
                'pixel size(mm)': avg_pixel,
                'head circumference (mm)': avg_hc
            })
        else:
            avg_pixel = subset['pixel size(mm)'].astype(float).mean()
            return pd.Series({
                'filename': f"{img_id}_HC.png",
                'pixel size(mm)': avg_pixel
            })
    return None

def get_HC_real(img_id: str):
    """Devuelve HC real (mm) si est√° disponible en el CSV de entrenamiento."""
    row = _select_row(_train_df, img_id)
    if row is None:
        return None
    return float(row.get('head circumference (mm)', np.nan)) if 'head circumference (mm)' in row.index else None

def load_sample_with_scaling(img_id: str, target_size: int = 256):
    """Carga imagen asociada al id y ajusta escalado devolviendo pixel_size corregido.

    Retorna: img_norm (float32 [target_size,target_size]), pixel_size_corr (mm/px), orig_w, orig_h
    """
    # Buscar fila en train primero, luego test
    row = _select_row(_train_df, img_id)
    source_df = 'train'
    if row is None:
        row = _select_row(_test_df, img_id)
        source_df = 'test'
    if row is None:
        raise FileNotFoundError(f"No hay metadatos para id {img_id}")

    filename = row['filename']
    pixel_size = float(row['pixel size(mm)'])

    # Construir ruta
    possible_paths = [
        os.path.join(TRAIN_DIR, filename),
        os.path.join(TEST_DIR, filename)
    ]
    img_path = None
    for p in possible_paths:
        if os.path.isfile(p):
            img_path = p
            break
    if img_path is None:
        raise FileNotFoundError(f"Imagen '{filename}' no encontrada en train/test set")

    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"Error leyendo imagen {img_path}")

    orig_h, orig_w = img.shape

    # Redimensionar manteniendo proporci√≥n (interpolaci√≥n √°rea)
    resized = cv2.resize(img, (target_size, target_size), interpolation=cv2.INTER_AREA)

    # Ajustar pixel size por factor de escala promedio
    scale_x = orig_w / target_size
    scale_y = orig_h / target_size
    scale_avg = (scale_x + scale_y) / 2.0
    pixel_size_corr = pixel_size * scale_avg

    # Normalizar igual que entrenamiento (0-1)
    resized_norm = (resized.astype(np.float32) / 255.0)

    return resized_norm, pixel_size_corr, orig_w, orig_h

# ==============================================================
# ETAPA 1: POST-PROCESAMIENTO MEJORADO CON RECONSTRUCCI√ìN
# ==============================================================

def reconstruir_contorno_fragmentado(contorno, img_shape, num_puntos=360):
    """
    Reconstruye un contorno fragmentado interpolando puntos faltantes
    usando ajuste de elipse y completando gaps.
    """
    if len(contorno) < 5:
        return contorno
    
    try:
        # Ajustar elipse inicial
        ellipse = cv2.fitEllipse(contorno)
        (cx, cy), (major, minor), angle = ellipse
        
        # Generar puntos de elipse te√≥rica
        theta = np.linspace(0, 2*np.pi, num_puntos)
        a = major / 2
        b = minor / 2
        angle_rad = np.deg2rad(angle)
        
        # Puntos de elipse rotados
        x_ellipse = cx + a * np.cos(theta) * np.cos(angle_rad) - b * np.sin(theta) * np.sin(angle_rad)
        y_ellipse = cy + a * np.cos(theta) * np.sin(angle_rad) + b * np.sin(theta) * np.cos(angle_rad)
        
        # Crear contorno reconstruido
        contorno_reconstruido = np.array([[int(x), int(y)] for x, y in zip(x_ellipse, y_ellipse)], dtype=np.int32)
        contorno_reconstruido = contorno_reconstruido.reshape(-1, 1, 2)
        
        return contorno_reconstruido
        
    except Exception:
        return contorno

def completar_contorno_con_convex_hull(contorno, binary_mask):
    """
    Usa convex hull para completar contornos muy fragmentados
    """
    try:
        hull = cv2.convexHull(contorno)
        return hull
    except Exception:
        return contorno

def unir_contornos_fragmentados(contours, img_shape, distancia_max=50):
    """
    Une m√∫ltiples fragmentos de contorno que probablemente pertenecen al mismo objeto.
    """
    if len(contours) <= 1:
        return contours
    
    # Ordenar por √°rea descendente
    contours_sorted = sorted(contours, key=cv2.contourArea, reverse=True)
    
    # Tomar los contornos m√°s grandes
    contornos_principales = []
    area_total = sum(cv2.contourArea(c) for c in contours_sorted)
    area_acumulada = 0
    
    for c in contours_sorted:
        area = cv2.contourArea(c)
        if area > area_total * 0.05:  # Solo contornos > 5% del √°rea total
            contornos_principales.append(c)
            area_acumulada += area
        if area_acumulada > area_total * 0.9:  # Cuando tengamos 90% del √°rea
            break
    
    if len(contornos_principales) <= 1:
        return contornos_principales if contornos_principales else contours_sorted[:1]
    
    # Unir contornos cercanos
    all_points = np.vstack(contornos_principales)
    
    return [all_points]

def refinar_prediccion_unet_v2(pred_raw, umbral_confianza=0.3):
    """
    Post-procesamiento optimizado para HC18.
    Versi√≥n conservadora que preserva el tama√±o original del contorno.
    """
    pred_norm = cv2.normalize(pred_raw, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    # Umbralizaci√≥n 
    _, binary = cv2.threshold(pred_norm, int(umbral_confianza * 255), 255, cv2.THRESH_BINARY)

    # Morfolog√≠a CONSERVADORA para cerrar gaps sin agrandar mucho
    kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    kernel_medium = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))

    # Cerrar gaps peque√±os
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_small, iterations=2)
    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_medium, iterations=1)
    
    # Verificar si el contorno se puede cerrar con fill holes
    binary_filled = ndimage.binary_fill_holes(binary).astype(np.uint8) * 255
    
    # Si fill_holes funcion√≥ (√°rea aument√≥ significativamente), tenemos un contorno cerrado
    area_original = np.sum(binary > 0)
    area_filled = np.sum(binary_filled > 0)
    
    if area_filled > area_original * 1.5:
        # El contorno se cerr√≥ bien, usar la versi√≥n rellena
        binary_final_region = binary_filled
    else:
        # El contorno est√° muy fragmentado, necesita dilataci√≥n m√°s agresiva
        kernel_connect = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
        binary_dilated = cv2.dilate(binary, kernel_connect, iterations=2)
        binary_filled_2 = ndimage.binary_fill_holes(binary_dilated).astype(np.uint8) * 255
        
        # Erosionar para recuperar tama√±o aproximado
        binary_eroded = cv2.erode(binary_filled_2, kernel_connect, iterations=2)
        
        if np.sum(binary_eroded) > area_original * 0.5:
            binary_final_region = binary_eroded
        else:
            # Erosi√≥n suave
            kernel_smaller = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
            binary_eroded_soft = cv2.erode(binary_filled_2, kernel_smaller, iterations=2)
            binary_final_region = binary_eroded_soft if np.sum(binary_eroded_soft) > area_original * 0.5 else binary_filled_2

    # Limpiar ruido peque√±o
    binary_clean = morphology.remove_small_objects(
        binary_final_region.astype(bool),
        min_size=300
    ).astype(np.uint8) * 255

    # Suavizado muy suave
    binary_smooth = cv2.GaussianBlur(binary_clean, (3, 3), 0.5)
    _, binary_final = cv2.threshold(binary_smooth, 127, 255, cv2.THRESH_BINARY)

    return binary_final, pred_norm

def refinar_prediccion_multiescala(pred_raw, umbrales=[0.2, 0.3, 0.4, 0.5]):
    """
    Procesa la predicci√≥n con m√∫ltiples umbrales y combina resultados
    para mejor detecci√≥n de contornos fragmentados.
    Convierte bordes a regiones s√≥lidas para mejor detecci√≥n.
    """
    pred_norm = cv2.normalize(pred_raw, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    
    # Acumulador de m√°scaras
    mask_acumulada = np.zeros_like(pred_norm, dtype=np.float32)
    
    for umbral in umbrales:
        _, binary = cv2.threshold(pred_norm, int(umbral * 255), 255, cv2.THRESH_BINARY)
        
        # Operaciones morfol√≥gicas para cerrar gaps
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=3)
        
        # Dilatar para conectar bordes
        kernel_connect = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (13, 13))
        binary = cv2.dilate(binary, kernel_connect, iterations=2)
        
        # Rellenar huecos
        binary = ndimage.binary_fill_holes(binary).astype(np.uint8) * 255
        
        # Erosionar para recuperar tama√±o
        binary = cv2.erode(binary, kernel_connect, iterations=2)
        
        # Acumular con peso basado en el umbral
        peso = 1.0 - abs(umbral - 0.35)  # Dar m√°s peso a umbrales cercanos a 0.35
        mask_acumulada += binary.astype(np.float32) * peso
    
    # Normalizar y binarizar
    mask_acumulada = cv2.normalize(mask_acumulada, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    _, mask_final = cv2.threshold(mask_acumulada, 127, 255, cv2.THRESH_BINARY)
    
    # Limpiar ruido
    mask_clean = morphology.remove_small_objects(
        mask_final.astype(bool),
        min_size=500
    ).astype(np.uint8) * 255
    
    return mask_clean, pred_norm

# ==============================================================
# ETAPA 2: DETECCI√ìN CON VALIDACI√ìN ADAPTATIVA Y AJUSTE ROBUSTO
# ==============================================================

def ajustar_elipse_desde_intensidad(pred_norm, umbral=0.3):
    """
    Ajusta una elipse directamente desde los p√≠xeles de alta intensidad
    de la predicci√≥n, sin necesidad de un contorno cerrado.
    
    Usa umbrales m√°s altos para evitar incluir ruido.
    """
    mejores_candidatos = []
    
    # Usar umbrales m√°s altos para ser m√°s selectivo
    for u in [0.35, 0.40, 0.45, 0.50, 0.55]:
        umbral_valor = int(u * 255)
        puntos_y, puntos_x = np.where(pred_norm > umbral_valor)
        
        if len(puntos_x) < 30:
            continue
        
        # Crear array de puntos
        puntos = np.column_stack([puntos_x, puntos_y]).astype(np.int32)
        puntos = puntos.reshape(-1, 1, 2)
        
        try:
            ellipse = cv2.fitEllipse(puntos)
            (cx, cy), (major, minor), angle = ellipse
            
            # Validar elipse razonable - m√°s restrictivo
            if major < 40 or minor < 30:
                continue
            if major > 350 or minor > 280:
                continue
            
            aspect_ratio = max(major, minor) / (min(major, minor) + 1e-6)
            if aspect_ratio > 1.8:  # M√°s restrictivo
                continue
            
            # Score basado en aspect ratio (preferir m√°s circular)
            score = 1.0 / aspect_ratio
            
            # Bonus por estar centrado
            dist_centro = np.sqrt((cx - 128)**2 + (cy - 128)**2) / 128
            score *= (1.0 - 0.3 * min(dist_centro, 1.0))
            
            # Penalizar elipses muy grandes (probablemente incluyen ruido)
            # El √°rea t√≠pica de una cabeza fetal en 256x256 es ~20-40% de la imagen
            area_elipse = np.pi * (major/2) * (minor/2)
            area_imagen = 256 * 256
            ratio_area = area_elipse / area_imagen
            
            if ratio_area > 0.5:  # Si ocupa m√°s del 50%, probablemente es ruido
                score *= 0.5
            elif ratio_area < 0.08:  # Muy peque√±a
                score *= 0.7
            
            mejores_candidatos.append((ellipse, score, u))
        except:
            continue
    
    if not mejores_candidatos:
        return None
    
    # Seleccionar la mejor elipse
    mejor = max(mejores_candidatos, key=lambda x: x[1])
    return mejor[0]

def ajustar_elipse_desde_skeleton(binary_mask):
    """
    Ajusta una elipse desde el esqueleto de la m√°scara binaria.
    El esqueleto representa la l√≠nea central del borde detectado.
    """
    from skimage.morphology import skeletonize
    
    skeleton = skeletonize(binary_mask > 0).astype(np.uint8) * 255
    
    # Obtener puntos del esqueleto
    puntos_y, puntos_x = np.where(skeleton > 0)
    
    if len(puntos_x) < 10:
        return None
    
    puntos = np.column_stack([puntos_x, puntos_y]).astype(np.int32)
    puntos = puntos.reshape(-1, 1, 2)
    
    try:
        ellipse = cv2.fitEllipse(puntos)
        return ellipse
    except:
        return None

def ajustar_elipse_ransac(contorno, n_iter=100, threshold=5.0):
    """
    Ajuste robusto de elipse usando RANSAC para ignorar outliers.
    Especialmente √∫til cuando el contorno tiene fragmentos incorrectos.
    """
    if len(contorno) < 10:
        return cv2.fitEllipse(contorno) if len(contorno) >= 5 else None
    
    puntos = contorno.reshape(-1, 2).astype(np.float32)
    n_puntos = len(puntos)
    
    mejor_elipse = None
    mejor_inliers = 0
    
    for _ in range(n_iter):
        # Seleccionar 5 puntos aleatorios (m√≠nimo para elipse)
        indices = np.random.choice(n_puntos, min(20, n_puntos), replace=False)
        muestra = puntos[indices].reshape(-1, 1, 2).astype(np.int32)
        
        try:
            elipse_candidata = cv2.fitEllipse(muestra)
            (cx, cy), (major, minor), angle = elipse_candidata
            
            # Validar elipse razonable
            if major < 10 or minor < 10 or major/minor > 3:
                continue
            
            # Contar inliers
            a = major / 2
            b = minor / 2
            angle_rad = np.deg2rad(angle)
            cos_a = np.cos(angle_rad)
            sin_a = np.sin(angle_rad)
            
            # Distancia de cada punto a la elipse
            inliers = 0
            for px, py in puntos:
                # Transformar al sistema de la elipse
                dx = px - cx
                dy = py - cy
                x_rot = dx * cos_a + dy * sin_a
                y_rot = -dx * sin_a + dy * cos_a
                
                # Distancia normalizada a la elipse
                dist = abs((x_rot/a)**2 + (y_rot/b)**2 - 1) * min(a, b)
                
                if dist < threshold:
                    inliers += 1
            
            if inliers > mejor_inliers:
                mejor_inliers = inliers
                mejor_elipse = elipse_candidata
                
        except Exception:
            continue
    
    # Si RANSAC no encontr√≥ buena elipse, usar m√©todo est√°ndar
    if mejor_elipse is None or mejor_inliers < n_puntos * 0.3:
        try:
            return cv2.fitEllipse(contorno)
        except:
            return None
    
    return mejor_elipse

def ajustar_elipse_pca(contorno):
    """
    Ajuste de elipse usando PCA para casos muy fragmentados.
    M√°s robusto a outliers que el m√©todo directo.
    """
    if len(contorno) < 5:
        return None
    
    puntos = contorno.reshape(-1, 2).astype(np.float64)
    
    # Centro de masa
    cx, cy = np.mean(puntos, axis=0)
    
    # Centrar puntos
    puntos_centrados = puntos - [cx, cy]
    
    # PCA
    cov_matrix = np.cov(puntos_centrados.T)
    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)
    
    # Ordenar por eigenvalue descendente
    idx = np.argsort(eigenvalues)[::-1]
    eigenvalues = eigenvalues[idx]
    eigenvectors = eigenvectors[:, idx]
    
    # Ejes de la elipse (usar factor para aproximar mejor el contorno)
    # El factor 2*sqrt se usa para convertir varianza a semi-eje
    factor = 2.5  # Ajustado emp√≠ricamente para HC
    major = factor * np.sqrt(eigenvalues[0])
    minor = factor * np.sqrt(eigenvalues[1])
    
    # √Ångulo
    angle = np.rad2deg(np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0]))
    
    return ((cx, cy), (major * 2, minor * 2), angle)

def combinar_ajustes_elipse(contorno, pred_norm=None, binary_mask=None, circularidad_contorno=None):
    """
    Combina m√∫ltiples m√©todos de ajuste de elipse y selecciona el mejor.
    Incluye m√©todos basados en intensidad para contornos fragmentados.
    
    Si circularidad_contorno es alta (>0.6), prioriza m√©todos basados en contorno.
    Si circularidad_contorno es baja (<0.3), prioriza m√©todos basados en intensidad.
    """
    if len(contorno) < 5:
        return None, None
    
    candidatos = []
    
    # Calcular circularidad si no se proporciona
    if circularidad_contorno is None:
        area = cv2.contourArea(contorno)
        perimeter = cv2.arcLength(contorno, True)
        if perimeter > 0:
            circularidad_contorno = 4 * np.pi * area / (perimeter ** 2)
        else:
            circularidad_contorno = 0
    
    # M√©todo 1: OpenCV est√°ndar (siempre incluir)
    try:
        elipse_cv = cv2.fitEllipse(contorno)
        # Dar bonus si circularidad es alta
        bonus_circ = 1.0 + circularidad_contorno * 0.5
        candidatos.append(('opencv', elipse_cv, bonus_circ))
    except:
        pass
    
    # M√©todo 2: RANSAC (bueno para contornos con ruido)
    elipse_ransac = ajustar_elipse_ransac(contorno)
    if elipse_ransac:
        bonus_ransac = 1.0 + circularidad_contorno * 0.3
        candidatos.append(('ransac', elipse_ransac, bonus_ransac))
    
    # M√©todo 3: PCA (para contornos fragmentados)
    elipse_pca = ajustar_elipse_pca(contorno)
    if elipse_pca:
        # Mejor para circularidad baja
        bonus_pca = 1.0 + (1.0 - circularidad_contorno) * 0.3
        candidatos.append(('pca', elipse_pca, bonus_pca))
    
    # M√©todo 4: Contorno reconstruido
    contorno_reconstruido = reconstruir_contorno_fragmentado(contorno, (256, 256))
    if len(contorno_reconstruido) >= 5:
        try:
            elipse_reconstruida = cv2.fitEllipse(contorno_reconstruido)
            # Mejor para circularidad media-baja
            bonus_rec = 1.0 + (0.5 - min(circularidad_contorno, 0.5)) * 0.4
            candidatos.append(('reconstruido', elipse_reconstruida, bonus_rec))
        except:
            pass
    
    # M√©todo 5: Desde intensidad (SOLO para contornos muy fragmentados)
    if pred_norm is not None and circularidad_contorno < 0.4:
        elipse_intensidad = ajustar_elipse_desde_intensidad(pred_norm, umbral=0.35)
        if elipse_intensidad:
            (cx_i, cy_i), (maj_i, min_i), _ = elipse_intensidad
            # Penalizar elipses grandes (probablemente incluyen ruido)
            area_ratio = (np.pi * maj_i * min_i / 4) / (256 * 256)
            if area_ratio < 0.45:  # Solo si no es demasiado grande
                bonus_int = 1.0 + (0.4 - circularidad_contorno) * 1.2
                candidatos.append(('intensidad', elipse_intensidad, bonus_int))
    
    # M√©todo 6: Desde skeleton (para contornos fragmentados)
    # Dar m√°s oportunidad al skeleton que suele ser m√°s preciso
    if binary_mask is not None and circularidad_contorno < 0.4:
        elipse_skeleton = ajustar_elipse_desde_skeleton(binary_mask)
        if elipse_skeleton:
            bonus_skel = 1.0 + (0.4 - circularidad_contorno) * 1.8  # Mayor bonus
            candidatos.append(('skeleton', elipse_skeleton, bonus_skel))
    
    if not candidatos:
        return None, None
    
    # Evaluar cada candidato
    def evaluar_elipse(elipse, contorno_original, bonus=1.0):
        (cx, cy), (major, minor), angle = elipse
        
        # Penalizar elipses muy exc√©ntricas
        aspect_ratio = max(major, minor) / (min(major, minor) + 1e-6)
        if aspect_ratio > 2.5:
            return -1
        
        # Penalizar elipses demasiado peque√±as o grandes
        if major < 30 or minor < 20:
            return -0.5
        if major > 500 or minor > 400:
            return -0.5
        
        # Calcular qu√© tan bien la elipse cubre el contorno
        puntos = contorno_original.reshape(-1, 2)
        
        a = major / 2
        b = minor / 2
        angle_rad = np.deg2rad(angle)
        cos_a = np.cos(angle_rad)
        sin_a = np.sin(angle_rad)
        
        distancias = []
        for px, py in puntos:
            dx = px - cx
            dy = py - cy
            x_rot = dx * cos_a + dy * sin_a
            y_rot = -dx * sin_a + dy * cos_a
            dist = abs((x_rot/a)**2 + (y_rot/b)**2 - 1)
            distancias.append(dist)
        
        # Score basado en distancia media y desviaci√≥n
        dist_media = np.mean(distancias)
        dist_std = np.std(distancias)
        
        score = 1.0 / (1.0 + dist_media + 0.5 * dist_std)
        
        # Bonus por aspect ratio cercano a 1
        score *= (1.0 / aspect_ratio)
        
        # Bonus si la elipse est√° centrada
        img_center = np.array([128, 128])
        dist_centro = np.linalg.norm(np.array([cx, cy]) - img_center) / 128
        score *= (1.0 - 0.3 * min(dist_centro, 1.0))
        
        # Aplicar bonus del m√©todo
        score *= bonus
        
        return score
    
    # Seleccionar mejor elipse
    mejor_score = -1
    mejor_elipse = None
    mejor_metodo = None
    
    for metodo, elipse, bonus in candidatos:
        score = evaluar_elipse(elipse, contorno, bonus)
        if score > mejor_score:
            mejor_score = score
            mejor_elipse = elipse
            mejor_metodo = metodo
    
    return mejor_elipse, mejor_metodo

def detectar_contorno_adaptativo(binary_mask, pred_norm, HC_esperado=None, debug=True):
    """
    Detecci√≥n con umbrales adaptativos seg√∫n el tama√±o esperado.
    Ahora con soporte para contornos fragmentados.
    """
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

    if len(contours) == 0:
        if debug:
            print("   ‚ö†Ô∏è No se encontraron contornos")
        return None, None

    img_area = binary_mask.shape[0] * binary_mask.shape[1]

    if debug:
        print(f"   üìä Contornos encontrados: {len(contours)}")
    
    # Si hay m√∫ltiples contornos, intentar unirlos
    if len(contours) > 1:
        contours_unidos = unir_contornos_fragmentados(contours, binary_mask.shape)
        if debug:
            print(f"   üîó Contornos despu√©s de uni√≥n: {len(contours_unidos)}")
        contours = contours_unidos

    # Filtro adaptativo
    def validar_contorno_adaptativo(contorno, img_shape):
        """
        Validaci√≥n m√°s flexible basada en el dataset HC18
        Adaptada para contornos tipo borde (no rellenos)
        """
        if len(contorno) < 10:
            return False, {}

        area = cv2.contourArea(contorno)

        # Rango adaptativo de √°rea - m√°s permisivo para contornos tipo borde
        # Un contorno de borde tiene mucha menos √°rea que un √°rea rellena
        area_ratio = area / img_area

        # Permitir contornos m√°s peque√±os (desde 1% para bordes)
        if area_ratio < 0.01 or area_ratio > 0.75:
            if debug:
                print(f"      ‚úó √Årea fuera de rango: {area_ratio:.3f}")
            return False, {}

        try:
            if len(contorno) < 5:
                return False, {}

            ellipse = cv2.fitEllipse(contorno)
            (cx, cy), (major, minor), angle = ellipse

            # Aspect ratio m√°s permisivo (1.0 - 2.0)
            aspect_ratio = max(major, minor) / (min(major, minor) + 1e-6)
            if aspect_ratio > 2.5:  # Muy permisivo
                if debug:
                    print(f"      ‚úó AR muy alta: {aspect_ratio:.2f}")
                return False, {}

            # Circularidad m√°s permisiva
            perimeter = cv2.arcLength(contorno, True)
            if perimeter == 0:
                return False, {}

            circularity = 4 * np.pi * area / (perimeter ** 2)

            # Circularidad m√°s permisiva para contornos tipo borde
            # Los contornos tipo borde tienen circularidad m√°s baja
            if circularity < 0.15:  # Muy permisivo para bordes
                if debug:
                    print(f"      ‚úó Circularidad baja: {circularity:.3f}")
                return False, {}

            # Posici√≥n m√°s permisiva
            img_center = np.array([img_shape[1]/2, img_shape[0]/2])
            ellipse_center = np.array([cx, cy])
            center_distance = np.linalg.norm(ellipse_center - img_center)
            center_ratio = center_distance / max(img_shape)

            # Score simplificado
            score = (
                circularity * 0.4 +
                area_ratio * 0.3 +
                (1.0 - min(center_ratio, 0.5) / 0.5) * 0.2 +
                (1.0 / aspect_ratio) * 0.1  # Favorece c√≠rculos
            )

            metrics = {
                'area': area,
                'area_ratio': area_ratio,
                'circularity': circularity,
                'aspect_ratio': aspect_ratio,
                'center_ratio': center_ratio,
                'score': score,
                'ellipse': ellipse,
                'center': (cx, cy),
                'axes': (major, minor)
            }

            if debug:
                print(f"      ‚úì Candidato v√°lido: Circ={circularity:.3f}, AR={aspect_ratio:.2f}, "
                      f"Area={area_ratio:.3f}, Score={score:.3f}")

            return True, metrics

        except Exception as e:
            if debug:
                print(f"      ‚úó Error en validaci√≥n: {e}")
            return False, {}

    # Evaluar todos los contornos
    candidatos = []

    for i, cnt in enumerate(contours):
        if debug:
            print(f"   üîç Evaluando contorno {i+1}/{len(contours)}...")

        es_valido, metrics = validar_contorno_adaptativo(cnt, binary_mask.shape)

        if es_valido:
            candidatos.append((cnt, metrics))

    if not candidatos:
        if debug:
            print("   ‚ö†Ô∏è Ning√∫n contorno pas√≥ validaci√≥n (intentando modo de emergencia)")

        # MODO DE EMERGENCIA MEJORADO: Usar m√©todos robustos de ajuste de elipse
        if len(contours) > 0:
            contorno_mayor = max(contours, key=cv2.contourArea)

            if len(contorno_mayor) >= 5:
                try:
                    # Intentar primero con m√©todos robustos
                    elipse_robusta, metodo_usado = combinar_ajustes_elipse(
                        contorno_mayor, pred_norm, binary_mask
                    )
                    
                    if elipse_robusta is None:
                        elipse_robusta = cv2.fitEllipse(contorno_mayor)
                        metodo_usado = 'opencv_emergencia'

                    metrics_emergency = {
                        'area': cv2.contourArea(contorno_mayor),
                        'area_ratio': cv2.contourArea(contorno_mayor) / img_area,
                        'circularity': 0.0,
                        'aspect_ratio': 0.0,
                        'center_ratio': 0.0,
                        'score': 0.0,
                        'ellipse': elipse_robusta,
                        'metodo_elipse': metodo_usado,
                        'modo': 'emergencia'
                    }

                    if debug:
                        print(f"   üö® Usando modo de emergencia (m√©todo: {metodo_usado})")

                    return contorno_mayor, metrics_emergency
                except:
                    pass

        return None, None

    # Seleccionar mejor candidato
    mejor_contorno, mejores_metrics = max(candidatos, key=lambda x: x[1]['score'])
    
    # Solo aplicar m√©todos robustos si la circularidad es baja
    # Para contornos con buena circularidad, usar OpenCV est√°ndar que es m√°s preciso
    circularidad = mejores_metrics.get('circularity', 0)
    
    if circularidad < 0.7:
        # Contorno de calidad media-baja: intentar mejorar con m√©todos robustos
        if debug:
            print("   üîß Aplicando ajuste robusto de elipse (circularidad baja)...")
        
        elipse_robusta, metodo_usado = combinar_ajustes_elipse(
            mejor_contorno, pred_norm, binary_mask, circularidad
        )
        
        if elipse_robusta:
            mejores_metrics['ellipse'] = elipse_robusta
            mejores_metrics['metodo_elipse'] = metodo_usado
            if debug:
                print(f"   ‚úÖ M√©todo de elipse seleccionado: {metodo_usado}")
    else:
        # Contorno de buena calidad: usar OpenCV est√°ndar
        if debug:
            print("   ‚úÖ Usando m√©todo est√°ndar (circularidad alta)")
        mejores_metrics['metodo_elipse'] = 'opencv_standard'

    if debug:
        print(f"   ‚úÖ Mejor contorno seleccionado: Score={mejores_metrics['score']:.3f}")

    return mejor_contorno, mejores_metrics

# ==============================================================
# ETAPA 3: C√ÅLCULO DE HC ROBUSTO
# ==============================================================

def calcular_HC_robusto(contorno, ellipse, pixel_size, HC_esperado=None):
    """
    C√°lculo con m√∫ltiples m√©todos y selecci√≥n inteligente
    """
    (cx, cy), (major, minor), angle = ellipse

    # Asegurar que major > minor
    if major < minor:
        major, minor = minor, major

    # Conversi√≥n a mm
    a_mm = (major / 2) * pixel_size
    b_mm = (minor / 2) * pixel_size

    # M√©todo 1: Ramanujan (est√°ndar cl√≠nico)
    h = ((a_mm - b_mm)**2) / ((a_mm + b_mm)**2 + 1e-10)
    HC_ramanujan = np.pi * (a_mm + b_mm) * (1 + (3*h) / (10 + np.sqrt(4 - 3*h) + 1e-10))

    # M√©todo 2: Per√≠metro del contorno
    perimetro_px = cv2.arcLength(contorno, True)
    HC_contorno = perimetro_px * pixel_size

    # M√©todo 3: Aproximaci√≥n exacta
    HC_exact = np.pi * (a_mm + b_mm) * (1 + h/4 + h**2/64 + h**3/256)

    # Selecci√≥n inteligente
    # Si el contorno es muy fragmentado, confiar m√°s en la elipse
    circularity = 4 * np.pi * cv2.contourArea(contorno) / (perimetro_px**2 + 1e-10)

    # Para contornos de alta calidad, usar principalmente Ramanujan (est√°ndar cl√≠nico)
    # El per√≠metro del contorno puede estar afectado por el post-procesamiento
    if circularity > 0.80:
        # Contorno limpio -> Ramanujan es m√°s confiable
        HC_final = HC_ramanujan
        metodo = 'ramanujan'
    elif circularity > 0.60:
        # Contorno aceptable -> Ramanujan con peque√±o ajuste
        HC_final = HC_ramanujan
        metodo = 'ramanujan'
    else:
        # Contorno fragmentado -> solo Ramanujan
        HC_final = HC_ramanujan
        metodo = 'ramanujan'

    # BPD y OFD
    BPD_mm = minor * pixel_size
    OFD_mm = major * pixel_size

    stats = {
        'HC_mm': HC_final,
        'HC_ramanujan': HC_ramanujan,
        'HC_contorno': HC_contorno,
        'HC_exact': HC_exact,
        'BPD_mm': BPD_mm,
        'OFD_mm': OFD_mm,
        'aspect_ratio': major / minor,
        'circularity': circularity,      
        'metodo_usado': metodo
    }

    if HC_esperado:
        error_abs = abs(HC_final - HC_esperado)
        error_pct = (error_abs / HC_esperado) * 100
        stats['error_abs'] = error_abs
        stats['error_pct'] = error_pct

        emoji = '‚úÖ' if error_pct < 5 else '‚úì' if error_pct < 10 else '‚ö†Ô∏è'
        print(f"   {emoji} HC={HC_final:.2f}mm (Real={HC_esperado:.2f}mm, Error={error_pct:.2f}%)")
        print(f"   üìä Ramanujan={HC_ramanujan:.2f}, Contorno={HC_contorno:.2f}, Exacto={HC_exact:.2f}")

    return HC_final, BPD_mm, stats

# ==============================================================
# PIPELINE COMPLETO OPTIMIZADO
# ==============================================================

def medir_HC_pipeline_optimizado(pred_raw, pixel_size, HC_esperado=None, visualizar=False, debug=True):
    """
    Pipeline optimizado con fallbacks y detecci√≥n multi-escala
    """
    if debug:
        print(f"\n{'‚îÄ'*70}")
        print("üî¨ PIPELINE OPTIMIZADO - GRADO M√âDICO V2")
        print(f"{'‚îÄ'*70}")

    # Etapa 1: Post-procesamiento est√°ndar
    if debug:
        print("üìç Etapa 1: Post-procesamiento de predicci√≥n...")

    binary_mask, pred_norm = refinar_prediccion_unet_v2(pred_raw, umbral_confianza=0.3)

    # Etapa 2: Detecci√≥n de contorno
    if debug:
        print("üìç Etapa 2: Detecci√≥n de contorno...")

    contorno, metrics = detectar_contorno_adaptativo(binary_mask, pred_norm, HC_esperado, debug=debug)

    # Si falla, intentar con detecci√≥n multi-escala
    if contorno is None or (metrics and metrics.get('score', 0) < 0.3):
        if debug:
            print("üìç Etapa 2b: Intentando detecci√≥n multi-escala...")
        
        binary_mask_multi, _ = refinar_prediccion_multiescala(pred_raw)
        contorno_multi, metrics_multi = detectar_contorno_adaptativo(
            binary_mask_multi, pred_norm, HC_esperado, debug=debug
        )
        
        # Usar resultado multi-escala si es mejor
        if contorno_multi is not None:
            if contorno is None or (metrics_multi and metrics_multi.get('score', 0) > metrics.get('score', 0)):
                contorno = contorno_multi
                metrics = metrics_multi
                binary_mask = binary_mask_multi
                if debug:
                    print("   ‚úÖ Usando resultado de detecci√≥n multi-escala")

    if contorno is None:
        print("‚ùå FALLO: No se pudo detectar contorno v√°lido")

        if visualizar:
            # Mostrar diagn√≥stico
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            axes[0].imshow(pred_raw, cmap='hot')
            axes[0].set_title('Predicci√≥n Original')
            axes[0].axis('off')

            axes[1].imshow(pred_norm, cmap='gray')
            axes[1].set_title('Normalizada')
            axes[1].axis('off')

            axes[2].imshow(binary_mask, cmap='gray')
            axes[2].set_title('M√°scara Binaria (sin contornos v√°lidos)')
            axes[2].axis('off')

            plt.tight_layout()
            plt.show()

        return None, None, None, None

    # Etapa 3: Ajuste de elipse (ya mejorado en detectar_contorno_adaptativo)
    if debug:
        print("üìç Etapa 3: Ajuste de elipse...")

    ellipse = metrics.get('ellipse')

    if ellipse is None:
        # Usar ajuste robusto como fallback
        ellipse, metodo = combinar_ajustes_elipse(contorno, pred_norm)
        if ellipse is None:
            ellipse = cv2.fitEllipse(contorno)
        metrics['metodo_elipse'] = metodo if metodo else 'opencv_fallback'

    # Etapa 4: C√°lculo de HC
    if debug:
        print("üìç Etapa 4: C√°lculo de HC...")

    HC_mm, BPD_mm, stats = calcular_HC_robusto(contorno, ellipse, pixel_size, HC_esperado)

    # Combinar m√©tricas
    stats.update(metrics)

    # Visualizaci√≥n
    if visualizar:
        visualizar_pipeline_detallado(pred_raw, pred_norm, binary_mask, contorno,
                                       ellipse, stats, HC_esperado)

    if debug:
        print(f"{'‚îÄ'*70}\n")

    return HC_mm, BPD_mm, ellipse, stats

# ==============================================================
# VISUALIZACI√ìN DETALLADA
# ==============================================================

def visualizar_pipeline_detallado(pred_raw, pred_norm, binary_mask, contorno,
                                   ellipse, stats, HC_esperado=None):
    """
    Visualizaci√≥n completa del pipeline
    """
    fig = plt.figure(figsize=(18, 10))
    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)

    # Fila 1: Procesamiento
    ax1 = fig.add_subplot(gs[0, 0])
    ax1.imshow(pred_raw, cmap='hot')
    ax1.set_title('1. Predicci√≥n U-Net', fontsize=10, fontweight='bold')
    ax1.axis('off')

    ax2 = fig.add_subplot(gs[0, 1])
    ax2.imshow(pred_norm, cmap='gray')
    ax2.set_title('2. Normalizada', fontsize=10, fontweight='bold')
    ax2.axis('off')

    ax3 = fig.add_subplot(gs[0, 2])
    ax3.imshow(binary_mask, cmap='gray')
    ax3.set_title('3. M√°scara Binaria', fontsize=10, fontweight='bold')
    ax3.axis('off')

    # Contorno detectado
    ax4 = fig.add_subplot(gs[0, 3])
    cont_img = cv2.cvtColor(pred_norm, cv2.COLOR_GRAY2BGR)
    cv2.drawContours(cont_img, [contorno], -1, (0, 255, 0), 2)
    ax4.imshow(cont_img)
    ax4.set_title('4. Contorno Detectado', fontsize=10, fontweight='bold')
    ax4.axis('off')

    # Fila 2: Resultados
    ax5 = fig.add_subplot(gs[1, 0])
    result_img = cv2.cvtColor(pred_norm, cv2.COLOR_GRAY2BGR)
    cv2.ellipse(result_img, ellipse, (0, 255, 255), 2)
    (cx, cy), _, _ = ellipse
    cv2.circle(result_img, (int(cx), int(cy)), 3, (255, 0, 0), -1)
    ax5.imshow(result_img)
    ax5.set_title('5. Elipse Ajustada', fontsize=10, fontweight='bold')
    ax5.axis('off')

    # Overlay
    ax6 = fig.add_subplot(gs[1, 1])
    overlay = cv2.addWeighted(
        cv2.cvtColor(pred_norm, cv2.COLOR_GRAY2BGR),
        0.7,
        cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR),
        0.3,
        0
    )
    cv2.ellipse(overlay, ellipse, (0, 255, 255), 2)
    ax6.imshow(overlay)
    ax6.set_title('6. Overlay', fontsize=10, fontweight='bold')
    ax6.axis('off')

    # Resultado final anotado
    ax7 = fig.add_subplot(gs[1, 2:])
    final_img = cv2.cvtColor((pred_norm * 0.7).astype(np.uint8), cv2.COLOR_GRAY2BGR)
    cv2.ellipse(final_img, ellipse, (0, 255, 255), 3)
    cv2.circle(final_img, (int(cx), int(cy)), 5, (255, 0, 0), -1)

    # Anotaciones
    y_pos = 30
    anotaciones = [
        f"HC: {stats['HC_mm']:.2f} mm",
        f"BPD: {stats['BPD_mm']:.2f} mm",
        f"OFD: {stats['OFD_mm']:.2f} mm",
    ]

    if HC_esperado:
        color = (0, 255, 0) if stats['error_pct'] < 5 else \
                (0, 255, 255) if stats['error_pct'] < 10 else (0, 0, 255)
        anotaciones.extend([
            f"Real: {HC_esperado:.2f} mm",
            f"Error: {stats['error_pct']:.2f}%"
        ])
    else:
        color = (0, 255, 255)

    for texto in anotaciones:
        cv2.putText(final_img, texto, (10, y_pos),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        y_pos += 35

    ax7.imshow(final_img)
    ax7.set_title('7. Resultado Final', fontsize=10, fontweight='bold')
    ax7.axis('off')

    # Fila 3: M√©tricas
    ax8 = fig.add_subplot(gs[2, :2])
    ax8.axis('off')

    metricas_texto = f"""
    M√âTRICAS DE CALIDAD:
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    ‚Ä¢ Circularidad: {stats.get('circularity', 0):.3f}
    ‚Ä¢ Aspect Ratio: {stats.get('aspect_ratio', 0):.2f}
    ‚Ä¢ √Årea (ratio): {stats.get('area_ratio', 0):.3f}
    ‚Ä¢ Quality Score: {stats.get('score', 0):.3f}

    M√âTODOS DE C√ÅLCULO:
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    ‚Ä¢ Ramanujan: {stats.get('HC_ramanujan', 0):.2f} mm
    ‚Ä¢ Contorno: {stats.get('HC_contorno', 0):.2f} mm
    ‚Ä¢ Exacto: {stats.get('HC_exact', 0):.2f} mm
    ‚Ä¢ M√©todo usado: {stats.get('metodo_usado', 'N/A')}
    """

    ax8.text(0.1, 0.5, metricas_texto, fontsize=10, family='monospace',
             verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    # Gr√°fico de comparaci√≥n
    if HC_esperado:
        ax9 = fig.add_subplot(gs[2, 2:])

        categorias = ['Predicho', 'Real']
        valores = [stats['HC_mm'], HC_esperado]
        colores = ['#00CED1', '#32CD32']

        bars = ax9.bar(categorias, valores, color=colores, alpha=0.7, edgecolor='black', linewidth=2)

        # Anotar valores
        for bar, valor in zip(bars, valores):
            height = bar.get_height()
            ax9.text(bar.get_x() + bar.get_width()/2., height,
                     f'{valor:.1f} mm',
                     ha='center', va='bottom', fontsize=12, fontweight='bold')

        ax9.set_ylabel('HC (mm)', fontsize=11, fontweight='bold')
        ax9.set_title(f'Comparaci√≥n (Error: {stats["error_pct"]:.2f}%)',
                      fontsize=10, fontweight='bold')
        ax9.grid(axis='y', alpha=0.3)
        ax9.set_ylim(0, max(valores) * 1.2)

    plt.suptitle('PIPELINE DE MEDICI√ìN DE HC - GRADO M√âDICO',
                 fontsize=14, fontweight='bold', y=0.98)

    plt.show()

# ==============================================================
# FUNCI√ìN DE PROCESAMIENTO
# ==============================================================

def procesar_con_pipeline_optimizado(image_names, visualizar_todos=False):
    """
    Procesa m√∫ltiples im√°genes con el pipeline optimizado
    """
    resultados = []

    for img_name in image_names:
        print(f"\n{'='*70}")
        print(f"üìÅ PROCESANDO: {img_name}")
        print('='*70)

        try:
            # Cargar imagen
            img, pixel_size, orig_w, orig_h = load_sample_with_scaling(img_name)
            HC_real = get_HC_real(img_name)

            print(f"üìê Dimensiones: {orig_w}x{orig_h} | Pixel: {pixel_size:.6f}mm")
            if HC_real:
                print(f"üéØ HC Real: {HC_real:.2f}mm")

            # Predicci√≥n
            pred = model.predict(np.expand_dims(img, axis=(0, -1)), verbose=0)[0].squeeze()

            # Pipeline
            HC_pred, BPD_pred, ellipse, stats = medir_HC_pipeline_optimizado(
                pred, pixel_size, HC_esperado=HC_real,
                visualizar=visualizar_todos, debug=True
            )

            if HC_pred and HC_real:
                resultados.append({
                    'nombre': img_name,
                    'HC_real': HC_real,
                    'HC_pred': HC_pred,
                    'BPD_pred': BPD_pred,
                    'stats': stats,
                    'ellipse': ellipse,
                    'img': img,
                    'pred': pred
                })

                print(f"‚úÖ √âXITO: HC predicho = {HC_pred:.2f}mm")

            elif HC_pred:
                print(f"‚ö†Ô∏è PARCIAL: HC predicho = {HC_pred:.2f}mm (sin ground truth)")
            else:
                print(f"‚ùå FALLO: No se pudo procesar la imagen")

        except Exception as e:
            print(f"‚ùå ERROR CR√çTICO: {str(e)}")
            import traceback
            traceback.print_exc()

    return resultados

# ==============================================================
# EJECUCI√ìN
# ==============================================================

def main():
    # Bloque de salida decorativa (con fallback ascii si encoding falla)
    try:
        print("\n" + "üöÄ "*20)
        print("INICIANDO PROCESAMIENTO CON PIPELINE OPTIMIZADO V2")
        print("üöÄ "*20 + "\n")
    except UnicodeEncodeError:
        print("\n" + "ROCKET "*10)
        print("INICIANDO PROCESAMIENTO CON PIPELINE OPTIMIZADO V2")
        print("ROCKET "*10 + "\n")

    # Im√°genes de prueba
    imagenes_test = ["001", "002", "300", "042"]
    return procesar_con_pipeline_optimizado(imagenes_test, visualizar_todos=True)

if __name__ == "__main__":
    resultados = main()

# ==============================================================
# RESUMEN
# ==============================================================

if __name__ == "__main__":
    if resultados:
        print("\n" + "="*110)
        print("RESULTADOS FINALES - PIPELINE OPTIMIZADO")
        print("="*110)
        print(f"{'Img':<8} {'HC Real':<10} {'HC Pred':<10} {'Error(mm)':<12} {'Error(%)':<10} {'Circ':<8} {'M√©todo':<10}")
        print("-"*110)

        errores = []
        for res in resultados:
            emoji = 'OK' if res['stats']['error_pct'] < 5 else 'MED' if res['stats']['error_pct'] < 10 else 'WARN'
            print(f"{res['nombre']:<8} {res['HC_real']:<10.2f} {res['HC_pred']:<10.2f} "
                  f"{res['stats']['error_abs']:<12.2f} {res['stats']['error_pct']:<10.2f} "
                  f"{res['stats'].get('circularity', 0):<8.3f} "
                  f"{res['stats'].get('metodo_usado', 'N/A'):<10} {emoji}")
            errores.append(res['stats']['error_pct'])

        print("="*110)
        print(f"\nESTAD√çSTICAS GLOBALES:")
        print(f"   ‚Ä¢ Procesadas exitosamente: {len(resultados)}")
        print(f"   ‚Ä¢ Error promedio: {np.mean(errores):.2f}%")
        print(f"   ‚Ä¢ Error mediano: {np.median(errores):.2f}%")
        print(f"   ‚Ä¢ Desviaci√≥n est√°ndar: {np.std(errores):.2f}%")
        print(f"   ‚Ä¢ Rango: [{np.min(errores):.2f}% - {np.max(errores):.2f}%]")

        exitos_5 = sum(1 for e in errores if e < 5)
        exitos_10 = sum(1 for e in errores if e < 10)

        print(f"\nPRECISI√ìN:")
        print(f"   ‚Ä¢ Error < 5%: {exitos_5}/{len(errores)} ({exitos_5/len(errores)*100:.1f}%)")
        print(f"   ‚Ä¢ Error < 10%: {exitos_10}/{len(errores)} ({exitos_10/len(errores)*100:.1f}%)")

        if np.mean(errores) < 5:
            print(f"\nPRECISI√ìN DE GRADO M√âDICO ALCANZADA")
        elif np.mean(errores) < 10:
            print(f"\nOBJETIVO CUMPLIDO (Error promedio < 10%)")
        else:
            print(f"\nProgreso: {100 - np.mean(errores):.1f}% de precisi√≥n")

        print("="*110)
    else:
        print("\nNo se obtuvieron resultados. Revisar diagn√≥stico...")